{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ness/Workspace/MLOnStage/deepLearning/perceptron/perceptron.py')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aider.coders import Coder \n",
    "from pathlib import Path\n",
    "pyproject_path = Path.cwd() / \"perceptron.py\"\n",
    "documentation = Path.cwd() / \"perceptron.md\"\n",
    "eng_design = Path.cwd() / \"perceptron_eng_design.md\"\n",
    "pyproject_path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/ness/Workspace/MLOnStage/deepLearning/perceptron/perceptron.py']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_editable = [\n",
    "    str(pyproject_path),    \n",
    "]\n",
    "context_editable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/ness/Workspace/MLOnStage/deepLearning/perceptron/perceptron.md',\n",
       " '/Users/ness/Workspace/MLOnStage/deepLearning/perceptron/perceptron_eng_design.md']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_read_only = [\n",
    "    str(documentation),\n",
    "    str(eng_design)\n",
    "]\n",
    "context_read_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List, Dict, Any\n",
    "from enum import Enum\n",
    "from datetime import datetime\n",
    "\n",
    "class CodeContext(BaseModel):\n",
    "    \"\"\"Structure for code-related context\"\"\"\n",
    "    language: str = Field(..., description=\"Programming language of the code\")\n",
    "    code: str = Field(..., description=\"The actual code snippet\")\n",
    "    file_path: Optional[str] = Field(None, description=\"Path to the file if applicable\")\n",
    "    dependencies: Optional[List[str]] = Field(default=[], description=\"Required dependencies\")\n",
    "\n",
    "class TaskMeta(BaseModel):\n",
    "    \"\"\"Meta object for AI coding tasks\"\"\"\n",
    "    \n",
    "    # Basic Task Information\n",
    "    id: str = Field(..., description=\"Unique identifier for the task\")\n",
    "    title: str = Field(..., description=\"Title of the task\")\n",
    "    description: str = Field(..., description=\"Detailed description of what needs to be done\")\n",
    "    context_file_paths: Optional[List[str]] = Field(\n",
    "        default=None, \n",
    "        description=\"Paths for read only files that contains related context\"\n",
    "    )\n",
    "    # Task Context\n",
    "    code_context: Optional[List[CodeContext]] = Field(\n",
    "        default=None, \n",
    "        description=\"Relevant code snippets and documentationcontext\"\n",
    "    )\n",
    "\n",
    "    requirements: Optional[List[str]] = Field(\n",
    "        default=None,\n",
    "        description=\"Requirements for the task\"\n",
    "    )\n",
    "    tags: Optional[List[str]] = Field(\n",
    "        default=None,\n",
    "        description=\"Tags for the task\"\n",
    "    )\n",
    "\n",
    "    def build_prompt(self) -> str:\n",
    "        \"\"\"\n",
    "        Builds a structured string prompt from the TaskMeta object.\n",
    "        \n",
    "        Returns:\n",
    "            str: A formatted string containing the structured prompt\n",
    "        \"\"\"\n",
    "        sections = []\n",
    "        \n",
    "        # Add task header with ID and title\n",
    "        sections.append(f\"# Task: {self.title} (ID: {self.id})\")\n",
    "        \n",
    "        # Add description if present\n",
    "        if self.description:\n",
    "            sections.append(\"\\n## Description\")\n",
    "            sections.append(self.description)\n",
    "        \n",
    "        # Add target files if present\n",
    "        if self.context_file_paths:\n",
    "            sections.append(\"\\n## Context read only Files\")\n",
    "            for file_path in self.context_file_paths:\n",
    "                sections.append(f\"- {file_path}\")\n",
    "        \n",
    "        # Add requirements if present\n",
    "        if self.requirements:\n",
    "            sections.append(\"\\n## Requirements\")\n",
    "            for req in self.requirements:\n",
    "                sections.append(f\"- {req}\")\n",
    "        \n",
    "        # Add code context if present\n",
    "        if self.code_context:\n",
    "            sections.append(\"\\n## Code Context\")\n",
    "            for idx, context in enumerate(self.code_context, 1):\n",
    "                # add code snippet header                \n",
    "                sections.append(f\"\\n### Code Snippet {idx}\")\n",
    "                # Specify language\n",
    "                sections.append(f\"Language: {context.language}\")\n",
    "                if context.dependencies:\n",
    "                    sections.append(\"Dependencies:\")\n",
    "                    for dep in context.dependencies:\n",
    "                        sections.append(f\"- {dep}\")\n",
    "                # Specify file path if available\n",
    "                if context.file_path:\n",
    "                    sections.append(\"file path:\")\n",
    "                    sections.append(f\"- {context.file_path}\")\n",
    "                # Add contents of the code snippet\n",
    "                sections.append(\"\\n```\" + context.language)\n",
    "                sections.append(context.code.strip())\n",
    "                sections.append(\"```\")\n",
    "        \n",
    "        # Add tags if present\n",
    "        if self.tags:\n",
    "            sections.append(\"\\n## Tags\")\n",
    "            sections.append(\", \".join(self.tags))\n",
    "        \n",
    "        # Join all sections with newlines\n",
    "        return \"\\n\".join(sections)\n",
    "\n",
    "    class Config:\n",
    "        \"\"\"Pydantic model configuration\"\"\"\n",
    "        arbitrary_types_allowed = True\n",
    "        json_encoders = {\n",
    "            datetime: lambda v: v.isoformat()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"id\":\"implement_base_class\",\"title\":\"Create Perceptron Base Class Structure\",\"description\":\"\\\\n    Create the basic Perceptron class with constructor and docstrings:\\\\n    1. Define class and constructor\\\\n    2. Add parameters: eta, n_iter, random_state\\\\n    3. Add class and method docstrings\\\\n    \",\"context_file_paths\":[\"/Users/ness/Workspace/MLOnStage/deepLearning/perceptron/perceptron.md\",\"/Users/ness/Workspace/MLOnStage/deepLearning/perceptron/perceptron_eng_design.md\"],\"code_context\":[{\"language\":\"python\",\"code\":\"\\\\n            class Perceptron:\\\\n                def __init__(self, eta=0.01, n_iter=50, random_state=1):\\\\n                    # TODO: Implement constructor\\\\n                    pass\\\\n            \",\"file_path\":\"/Users/ness/Workspace/MLOnStage/deepLearning/perceptron/perceptron.py\",\"dependencies\":[]}],\"requirements\":[\"Include learning rate parameter (eta)\",\"Include number of iterations parameter (n_iter)\",\"Include random seed parameter (random_state)\",\"Add proper docstrings following NumPy format\"],\"tags\":[\"perceptron\",\"class-structure\",\"initialization\"]}'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_1 = TaskMeta(\n",
    "    id=\"implement_base_class\",\n",
    "    title=\"Create Perceptron Base Class Structure\",\n",
    "    description=\"\"\"\n",
    "    Create the basic Perceptron class with constructor and docstrings:\n",
    "    1. Define class and constructor\n",
    "    2. Add parameters: eta, n_iter, random_state\n",
    "    3. Add class and method docstrings\n",
    "    \"\"\",\n",
    "    context_file_paths=context_read_only,\n",
    "    code_context=[\n",
    "        CodeContext(\n",
    "            language=\"python\",\n",
    "            code=\"\"\"\n",
    "            class Perceptron:\n",
    "                def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "                    # TODO: Implement constructor\n",
    "                    pass\n",
    "            \"\"\",\n",
    "            file_path=str(pyproject_path)\n",
    "        )\n",
    "    ],\n",
    "    requirements=[\n",
    "        \"Include learning rate parameter (eta)\",\n",
    "        \"Include number of iterations parameter (n_iter)\",\n",
    "        \"Include random seed parameter (random_state)\",\n",
    "        \"Add proper docstrings following NumPy format\"\n",
    "    ],\n",
    "    tags=[\"perceptron\", \"class-structure\", \"initialization\"]\n",
    ")\n",
    "task_1.model_dump_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Task: Create Perceptron Base Class Structure (ID: implement_base_class)\n",
      "\n",
      "## Description\n",
      "\n",
      "    Create the basic Perceptron class with constructor and docstrings:\n",
      "    1. Define class and constructor\n",
      "    2. Add parameters: eta, n_iter, random_state\n",
      "    3. Add class and method docstrings\n",
      "    \n",
      "\n",
      "## Context read only Files\n",
      "- /Users/ness/Workspace/MLOnStage/deepLearning/perceptron/perceptron.md\n",
      "- /Users/ness/Workspace/MLOnStage/deepLearning/perceptron/perceptron_eng_design.md\n",
      "\n",
      "## Requirements\n",
      "- Include learning rate parameter (eta)\n",
      "- Include number of iterations parameter (n_iter)\n",
      "- Include random seed parameter (random_state)\n",
      "- Add proper docstrings following NumPy format\n",
      "\n",
      "## Code Context\n",
      "\n",
      "### Code Snippet 1\n",
      "Language: python\n",
      "file path:\n",
      "- /Users/ness/Workspace/MLOnStage/deepLearning/perceptron/perceptron.py\n",
      "\n",
      "```python\n",
      "class Perceptron:\n",
      "                def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
      "                    # TODO: Implement constructor\n",
      "                    pass\n",
      "```\n",
      "\n",
      "## Tags\n",
      "perceptron, class-structure, initialization\n"
     ]
    }
   ],
   "source": [
    "# Generate the prompt\n",
    "prompt = task_1.build_prompt()\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll help implement the Perceptron base class structure. Looking at the existing file and requirements, I notice the docstring is already well-defined, so we just need to properly implement the constructor.\n",
      "\n",
      "Let's update the constructor to store the parameters as instance variables:\n",
      "\n",
      "deepLearning/perceptron/perceptron.py\n",
      "<source>python\n",
      "<<<<<<< SEARCH\n",
      "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
      "        self.eta = eta\n",
      "        self.n_iter = n_iter\n",
      "        self.random_state = random_state\n",
      "=======\n",
      "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
      "        \"\"\"Initialize Perceptron object.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        eta : float, default=0.01\n",
      "            Learning rate (between 0.0 and 1.0)\n",
      "        n_iter : int, default=50\n",
      "            Number of passes over the training dataset\n",
      "        random_state : int, default=1\n",
      "            Random number generator seed for reproducibility\n",
      "        \"\"\"\n",
      "        if not (0.0 <= eta <= 1.0):\n",
      "            raise ValueError('Learning rate must be between 0.0 and 1.0')\n",
      "        if not isinstance(n_iter, int) or n_iter <= 0:\n",
      "            raise ValueError('n_iter must be a positive integer')\n",
      "            \n",
      "        self.eta = eta\n",
      "        self.n_iter = n_iter\n",
      "        self.random_state = random_state\n",
      ">>>>>>> REPLACE\n",
      "</source>\n",
      "\n",
      "I've made the following improvements:\n",
      "\n",
      "1. Added method-level docstring following NumPy format\n",
      "2. Added input validation for eta and n_iter parameters\n",
      "3. Kept the same parameter assignments but with validation checks\n",
      "\n",
      "The class-level docstring was already well-defined so I left it unchanged. The implementation follows the engineering design document and adds proper error checking for the parameters."
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Tokens: 6.8k sent, 387 received. Cost: $0.03 message, $0.03 session.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Tokens: 6.8k sent, 387 received. Cost: $0.03 message, $0.03 session.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Applied edit to deepLearning/perceptron/perceptron.py\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Applied edit to deepLearning/perceptron/perceptron.py\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll help implement the Perceptron base class structure. Looking at the existing file and requirements, I notice the docstring is already well-defined, so we just need to properly implement the constructor.\n",
      "\n",
      "Let's update the constructor to store the parameters as instance variables:\n",
      "\n",
      "deepLearning/perceptron/perceptron.py\n",
      "<source>python\n",
      "<<<<<<< SEARCH\n",
      "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
      "        self.eta = eta\n",
      "        self.n_iter = n_iter\n",
      "        self.random_state = random_state\n",
      "=======\n",
      "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
      "        \"\"\"Initialize Perceptron object.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        eta : float, default=0.01\n",
      "            Learning rate (between 0.0 and 1.0)\n",
      "        n_iter : int, default=50\n",
      "            Number of passes over the training dataset\n",
      "        random_state : int, default=1\n",
      "            Random number generator seed for reproducibility\n",
      "        \"\"\"\n",
      "        if not (0.0 <= eta <= 1.0):\n",
      "            raise ValueError('Learning rate must be between 0.0 and 1.0')\n",
      "        if not isinstance(n_iter, int) or n_iter <= 0:\n",
      "            raise ValueError('n_iter must be a positive integer')\n",
      "            \n",
      "        self.eta = eta\n",
      "        self.n_iter = n_iter\n",
      "        self.random_state = random_state\n",
      ">>>>>>> REPLACE\n",
      "</source>\n",
      "\n",
      "I've made the following improvements:\n",
      "\n",
      "1. Added method-level docstring following NumPy format\n",
      "2. Added input validation for eta and n_iter parameters\n",
      "3. Kept the same parameter assignments but with validation checks\n",
      "\n",
      "The class-level docstring was already well-defined so I left it unchanged. The implementation follows the engineering design document and adds proper error checking for the parameters.\n"
     ]
    }
   ],
   "source": [
    "from aider.coders import Coder\n",
    "from aider.models import Model\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "model = Model(\"claude-3-5-sonnet-20241022\")\n",
    "# Initialize AI Coding Assistant\n",
    "coder = Coder.create(\n",
    "    main_model=model,\n",
    "    fnames=[task_1.code_context[0].file_path],\n",
    "    read_only_fnames=task_1.context_file_paths,\n",
    "    auto_commits=False,\n",
    "    suggest_shell_commands=False,\n",
    ")\n",
    "\n",
    "# # Run the task\n",
    "result = coder.run(task_1.build_prompt())\n",
    "\n",
    "# Print the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll help implement the core Perceptron methods. First, we need to add the numpy import at the top of the file, then implement the net_input and predict methods.\n",
      "\n",
      "deepLearning/perceptron/perceptron.py\n",
      "<source>python\n",
      "<<<<<<< SEARCH\n",
      "class Perceptron:\n",
      "=======\n",
      "import numpy as np\n",
      "\n",
      "class Perceptron:\n",
      ">>>>>>> REPLACE\n",
      "</source>\n",
      "\n",
      "Now let's implement the core methods:\n",
      "\n",
      "deepLearning/perceptron/perceptron.py\n",
      "<source>python\n",
      "<<<<<<< SEARCH\n",
      "    def net_input(self, X):\n",
      "                # TODO: Implement weighted sum calculation\n",
      "                pass\n",
      "                \n",
      "            def predict(self, X):\n",
      "                # TODO: Implement prediction logic\n",
      "                pass\n",
      "=======\n",
      "    def net_input(self, X):\n",
      "        \"\"\"Calculate net input.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like, shape = [n_examples, n_features]\n",
      "            Training vectors\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        float\n",
      "            Net input calculated as: w^T * x + b\n",
      "        \"\"\"\n",
      "        return np.dot(X, self.w_) + self.b_\n",
      "    \n",
      "    def predict(self, X):\n",
      "        \"\"\"Return class label after unit step.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like, shape = [n_examples, n_features]\n",
      "            Training vectors\n",
      "            \n",
      "        Returns\n",
      "        -------\n",
      "        ndarray, shape = [n_examples]\n",
      "            Predicted class labels\n",
      "        \"\"\"\n",
      "        return np.where(self.net_input(X) >= 0.0, 1, 0)\n",
      ">>>>>>> REPLACE\n",
      "</source>\n",
      "\n",
      "The changes include:\n",
      "\n",
      "1. Added numpy import at the top\n",
      "2. Implemented net_input() to:\n",
      "   - Calculate dot product between weights and input features\n",
      "   - Add bias term\n",
      "3. Implemented predict() to:\n",
      "   - Apply step function using np.where()\n",
      "   - Return 1 where net input >= 0, else 0\n",
      "4. Added proper docstrings following NumPy format\n",
      "5. Used numpy operations for efficient array handling\n",
      "\n",
      "The implementation follows the mathematical formulation from the perceptron.md document and the engineering specifications from perceptron_eng_design.md."
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Tokens: 7.5k sent, 420 received. Cost: $0.03 message, $0.05 session.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Tokens: 7.5k sent, 420 received. Cost: $0.03 message, $0.05 session.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">The LLM did not conform to the edit format.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mThe LLM did not conform to the edit format.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">https://aider.chat/docs/troubleshooting/edit-errors.html\n",
       "</pre>\n"
      ],
      "text/plain": [
       "https://aider.chat/docs/troubleshooting/edit-errors.html\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"># 1 SEARCH/REPLACE block failed to match!\n",
       "\n",
       "## SearchReplaceNoExactMatch: This SEARCH block failed to exactly match lines in \n",
       "deepLearning/perceptron/perceptron.py\n",
       "&lt;&lt;&lt;&lt;&lt;&lt;&lt; SEARCH\n",
       "    def net_input(self, X):\n",
       "                # TODO: Implement weighted sum calculation\n",
       "                pass\n",
       "                \n",
       "            def predict(self, X):\n",
       "                # TODO: Implement prediction logic\n",
       "                pass\n",
       "=======\n",
       "    def net_input(self, X):\n",
       "        \"\"\"Calculate net input.\n",
       "        \n",
       "        Parameters\n",
       "        ----------\n",
       "        X : array-like, shape = [n_examples, n_features]\n",
       "            Training vectors\n",
       "        \n",
       "        Returns\n",
       "        -------\n",
       "        float\n",
       "            Net input calculated as: w^T * x + b\n",
       "        \"\"\"\n",
       "        return np.dot(X, self.w_) + self.b_\n",
       "    \n",
       "    def predict(self, X):\n",
       "        \"\"\"Return class label after unit step.\n",
       "        \n",
       "        Parameters\n",
       "        ----------\n",
       "        X : array-like, shape = [n_examples, n_features]\n",
       "            Training vectors\n",
       "            \n",
       "        Returns\n",
       "        -------\n",
       "        ndarray, shape = [n_examples]\n",
       "            Predicted class labels\n",
       "        \"\"\"\n",
       "        return np.where(self.net_input(X) &gt;= 0.0, 1, 0)\n",
       "&gt;&gt;&gt;&gt;&gt;&gt;&gt; REPLACE\n",
       "\n",
       "The SEARCH section must exactly match an existing block of lines including all white space, comments, indentation, \n",
       "docstrings, etc\n",
       "\n",
       "# The other 1 SEARCH/REPLACE block were applied successfully.\n",
       "Don't re-send them.\n",
       "Just reply with fixed versions of the block above that failed to match.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "# 1 SEARCH/REPLACE block failed to match!\n",
       "\n",
       "## SearchReplaceNoExactMatch: This SEARCH block failed to exactly match lines in \n",
       "deepLearning/perceptron/perceptron.py\n",
       "<<<<<<< SEARCH\n",
       "    def net_input(self, X):\n",
       "                # TODO: Implement weighted sum calculation\n",
       "                pass\n",
       "                \n",
       "            def predict(self, X):\n",
       "                # TODO: Implement prediction logic\n",
       "                pass\n",
       "=======\n",
       "    def net_input(self, X):\n",
       "        \"\"\"Calculate net input.\n",
       "        \n",
       "        Parameters\n",
       "        ----------\n",
       "        X : array-like, shape = [n_examples, n_features]\n",
       "            Training vectors\n",
       "        \n",
       "        Returns\n",
       "        -------\n",
       "        float\n",
       "            Net input calculated as: w^T * x + b\n",
       "        \"\"\"\n",
       "        return np.dot(X, self.w_) + self.b_\n",
       "    \n",
       "    def predict(self, X):\n",
       "        \"\"\"Return class label after unit step.\n",
       "        \n",
       "        Parameters\n",
       "        ----------\n",
       "        X : array-like, shape = [n_examples, n_features]\n",
       "            Training vectors\n",
       "            \n",
       "        Returns\n",
       "        -------\n",
       "        ndarray, shape = [n_examples]\n",
       "            Predicted class labels\n",
       "        \"\"\"\n",
       "        return np.where(self.net_input(X) >= 0.0, 1, 0)\n",
       ">>>>>>> REPLACE\n",
       "\n",
       "The SEARCH section must exactly match an existing block of lines including all white space, comments, indentation, \n",
       "docstrings, etc\n",
       "\n",
       "# The other 1 SEARCH/REPLACE block were applied successfully.\n",
       "Don't re-send them.\n",
       "Just reply with fixed versions of the block above that failed to match.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let me fix the SEARCH/REPLACE block to match the exact content of the file and add the net_input and predict methods:\n",
      "\n",
      "deepLearning/perceptron/perceptron.py\n",
      "<source>python\n",
      "<<<<<<< SEARCH\n",
      "        self.eta = eta\n",
      "        self.n_iter = n_iter\n",
      "        self.random_state = random_state\n",
      "=======\n",
      "        self.eta = eta\n",
      "        self.n_iter = n_iter\n",
      "        self.random_state = random_state\n",
      "\n",
      "    def net_input(self, X):\n",
      "        \"\"\"Calculate net input.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like, shape = [n_examples, n_features]\n",
      "            Training vectors\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        float\n",
      "            Net input calculated as: w^T * x + b\n",
      "        \"\"\"\n",
      "        return np.dot(X, self.w_) + self.b_\n",
      "    \n",
      "    def predict(self, X):\n",
      "        \"\"\"Return class label after unit step.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like, shape = [n_examples, n_features]\n",
      "            Training vectors\n",
      "            \n",
      "        Returns\n",
      "        -------\n",
      "        ndarray, shape = [n_examples]\n",
      "            Predicted class labels\n",
      "        \"\"\"\n",
      "        return np.where(self.net_input(X) >= 0.0, 1, 0)\n",
      ">>>>>>> REPLACE\n",
      "</source>"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Tokens: 8.3k sent, 257 received. Cost: $0.03 message, $0.08 session.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Tokens: 8.3k sent, 257 received. Cost: $0.03 message, $0.08 session.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Applied edit to deepLearning/perceptron/perceptron.py\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Applied edit to deepLearning/perceptron/perceptron.py\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let me fix the SEARCH/REPLACE block to match the exact content of the file and add the net_input and predict methods:\n",
      "\n",
      "deepLearning/perceptron/perceptron.py\n",
      "<source>python\n",
      "<<<<<<< SEARCH\n",
      "        self.eta = eta\n",
      "        self.n_iter = n_iter\n",
      "        self.random_state = random_state\n",
      "=======\n",
      "        self.eta = eta\n",
      "        self.n_iter = n_iter\n",
      "        self.random_state = random_state\n",
      "\n",
      "    def net_input(self, X):\n",
      "        \"\"\"Calculate net input.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like, shape = [n_examples, n_features]\n",
      "            Training vectors\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        float\n",
      "            Net input calculated as: w^T * x + b\n",
      "        \"\"\"\n",
      "        return np.dot(X, self.w_) + self.b_\n",
      "    \n",
      "    def predict(self, X):\n",
      "        \"\"\"Return class label after unit step.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like, shape = [n_examples, n_features]\n",
      "            Training vectors\n",
      "            \n",
      "        Returns\n",
      "        -------\n",
      "        ndarray, shape = [n_examples]\n",
      "            Predicted class labels\n",
      "        \"\"\"\n",
      "        return np.where(self.net_input(X) >= 0.0, 1, 0)\n",
      ">>>>>>> REPLACE\n",
      "</source>\n"
     ]
    }
   ],
   "source": [
    "task_2 = TaskMeta(\n",
    "    id=\"implement_core_methods\",\n",
    "    title=\"Implement Core Perceptron Methods\",\n",
    "    description=\"\"\"\n",
    "    Implement the core computational methods for the Perceptron:\n",
    "    1. net_input(): Compute the weighted sum\n",
    "    2. predict(): Implement step function\n",
    "    \"\"\",\n",
    "    context_file_paths=context_read_only,\n",
    "    code_context=[\n",
    "        CodeContext(\n",
    "            language=\"python\",\n",
    "            code=\"\"\"\n",
    "            def net_input(self, X):\n",
    "                # TODO: Implement weighted sum calculation\n",
    "                pass\n",
    "                \n",
    "            def predict(self, X):\n",
    "                # TODO: Implement prediction logic\n",
    "                pass\n",
    "            \"\"\",\n",
    "            file_path=str(pyproject_path),\n",
    "            dependencies=[\"numpy\"]\n",
    "        )\n",
    "    ],\n",
    "    requirements=[\n",
    "        \"Implement vector dot product in net_input\",\n",
    "        \"Add bias term to net_input\",\n",
    "        \"Implement step function in predict\",\n",
    "        \"Handle numpy arrays efficiently\"\n",
    "    ],\n",
    "    tags=[\"perceptron\", \"core-methods\", \"numpy\"]\n",
    ")\n",
    "\n",
    "# # Run the task\n",
    "result = coder.run(task_2.build_prompt())\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aurora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
